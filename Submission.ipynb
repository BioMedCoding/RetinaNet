{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "La definizione del dataset è presente nel secondo specchio, evidenziata da appositi commenti"
      ],
      "metadata": {
        "id": "oj_mgXff2D2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ml_da2sW-O0C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from skimage import io,color, img_as_ubyte, exposure, filters, img_as_float, morphology, measure, restoration\n",
        "from scipy import ndimage\n",
        "from skimage.transform import resize\n",
        "from scipy.ndimage import gaussian_filter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from scipy.spatial import KDTree\n",
        "import skimage.draw\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nella sezione qui sotto vanno definiti due percorsi:\n",
        "  1.   working_folder, ovvero la cartella contenente tutti i file della submission. A partire da questa è indicato l'experiment_path dove è salvata la rete allenata.\n",
        "  2.   dataset_folder, ovvero l'indirizzo completo della cartella contenente le immagini da analizzare\n",
        "\n",
        "L'output del sistema crea una cartella all'interno della cartella della submission. Volendo è possibile cambiare questa impostazione cercando l'apposita variabile evidenziata in fondo al codice"
      ],
      "metadata": {
        "id": "us2bms4o0mSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Gruppo: Mattana, Olivotto, Pero, Tiraboschi\n",
        "\n",
        "#================================================== PERCORSO SUBMISSION ==========================================================================================================================\n",
        "working_folder = \"/content/drive/MyDrive/consegna\"\n",
        "#================================================== /PERCORSO SUBMISSION =========================================================================================================================\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Definizione valori relativi al salvataggio della rete neurale allenata\n",
        "experiment_id = '8rkvczpq'                                                        # Parametro per caricare la rete corrette, si lascia in questo modo per rispecchiare la struttura del codice usato durante l'allenamento e il test del sistema\n",
        "trial_id = 'VXh13'                                                                # Altro parametro per individuare la rete corretta, si lascia come indicato al commento sopra\n",
        "experiment_path =   working_folder + '/modelli_allenati/'+experiment_id           # Percorso contenente il salvataggio della rete allenata\n",
        "\n",
        "\n",
        "\n",
        "#================================================== PERCORSO DATASET ==========================================================================================================================\n",
        "\n",
        "dataset_folder = '/content/drive/MyDrive/RETINA/Original'                                           # Percorso in cui sono presenti le immagini da processare, relativo rispetto\n",
        "image_paths = [os.path.join(dataset_folder, fname) for fname in os.listdir(dataset_folder)]         # Vettore contenente tutti i nomi delle immagini\n",
        "\n",
        "# N.B. Se si vuole selezionare anche la cartella di output è possibile farlo andando a modificare l'apposita variabile evidenziata in fondo al codice, nell'ultima sezione\n",
        "\n",
        "#================================================== /PERCORSO DATASET =========================================================================================================================\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcgr-1BM-Qzc",
        "outputId": "45273edc-99b9-4cc7-fd86-72cd3e12d7b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definizione parametri postprocess\n",
        "v_bin = 0.5\n",
        "distance_threshold = 45\n",
        "thickness = 5\n",
        "\n",
        "block_size = (256,256) # Definizione dei blocchi in cui dividere\n",
        "\n",
        "# Definizione nome trial, nel caso di esecuzione su singolo trial\n",
        "nome_trial = experiment_id+'_'+trial_id\n",
        "model_path = experiment_path+'/'+trial_id\n",
        "print(nome_trial) # Stampa nome per conferma e controllo"
      ],
      "metadata": {
        "id": "xZCWLa1Q-UzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8852b59f-a975-498e-c2af-7f8dc79332af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8rkvczpq_VXh13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nella sezione seguente vengono definite tutte le funzioni usate in seguito, con eventuali commenti di spiegazione"
      ],
      "metadata": {
        "id": "GhIPsO552wOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_normalization(matrix):   #Funzione di normalizzazione usata in seguito\n",
        "    \"\"\"\n",
        "    Normalizza una matrice utilizzando la normalizzazione Min-Max.\n",
        "\n",
        "    Parametri:\n",
        "    - matrix: ndarray, la matrice da normalizzare\n",
        "\n",
        "    Restituisce:\n",
        "    - matrix_normalizzata: ndarray, la matrice normalizzata\n",
        "    \"\"\"\n",
        "    min_value = np.min(matrix)\n",
        "    max_value = np.max(matrix)\n",
        "\n",
        "    matrix_normalizzata = (matrix - min_value) / (max_value - min_value)\n",
        "\n",
        "    return matrix_normalizzata\n",
        "\n",
        "def draw_thick_line(pt1, pt2, thickness):\n",
        "    \"\"\"\n",
        "    Traccia una linea di spessore scelto tra i due punti indicati\n",
        "\n",
        "    Parametri:\n",
        "    - pt1, pt2: punti da colleggare\n",
        "    - thickness: spessore della linea da tracciare\n",
        "\n",
        "    Restituisce:\n",
        "    - rr_all, cc_all: coordinate modificate\n",
        "    \"\"\"\n",
        "    rr, cc = skimage.draw.line(int(pt1[0]), int(pt1[1]), int(pt2[0]), int(pt2[1]))\n",
        "    coords = [(rr, cc)]\n",
        "\n",
        "    for i in range(1, thickness):\n",
        "        # Calcolare le coordinate per linee aggiuntive\n",
        "        rr_offset1, cc_offset1 = skimage.draw.line(int(pt1[0]+i), int(pt1[1]), int(pt2[0]+i), int(pt2[1]))\n",
        "        rr_offset2, cc_offset2 = skimage.draw.line(int(pt1[0]-i), int(pt1[1]), int(pt2[0]-i), int(pt2[1]))\n",
        "        coords.append((rr_offset1, cc_offset1))\n",
        "        coords.append((rr_offset2, cc_offset2))\n",
        "\n",
        "    # Combinare tutte le coordinate\n",
        "    rr_all = np.concatenate([c[0] for c in coords])\n",
        "    cc_all = np.concatenate([c[1] for c in coords])\n",
        "\n",
        "    return rr_all, cc_all\n",
        "\n",
        "# Funzione per controllare se due bounding boxes sono abbastanza vicini, usato per il postprocess\n",
        "def boxes_are_close(box1, box2, threshold):\n",
        "    return (box1[2] >= box2[0] - threshold and box2[2] >= box1[0] - threshold and\n",
        "            box1[3] >= box2[1] - threshold and box2[3] >= box1[1] - threshold)\n",
        "\n",
        "# Funzione per il controllo del vicinato e ricerca KDTree, usato per il postprocess\n",
        "def check_and_search(region1, region2, tree1, tree2, box1, box2, threshold):\n",
        "    if boxes_are_close(box1, box2, threshold):\n",
        "        dist, idx2 = tree2.query(region1.coords, k=1, distance_upper_bound=threshold)\n",
        "        valid_indices = np.where(dist < threshold)[0]\n",
        "        if valid_indices.size > 0:\n",
        "            min_dist_idx = idx2[valid_indices[0]]\n",
        "            if min_dist_idx < len(region2.coords):\n",
        "                closest_point_region1 = region1.coords[valid_indices[0]]\n",
        "                closest_point_region2 = region2.coords[min_dist_idx]\n",
        "                return (closest_point_region1, closest_point_region2)\n",
        "    return None\n",
        "\n",
        "def remove_small_regions(binary_image, area_threshold):\n",
        "    \"\"\"\n",
        "    Rimuova zone da un'immagine binaria che hanno area inferiore al valore selezionato\n",
        "\n",
        "    Parametri:\n",
        "    - binary_image: immagine binaria su cui lavorare\n",
        "    - area_threshold: soglia di area sotto la quale si deve rimuovere\n",
        "\n",
        "    Restituisce:\n",
        "    - binary_image: immagine con zone rimosse\n",
        "    \"\"\"\n",
        "    # Label the image\n",
        "    labeled_image = measure.label(binary_image, connectivity=2)\n",
        "\n",
        "    # Get region properties\n",
        "    regions = measure.regionprops(labeled_image)\n",
        "\n",
        "    # Create a mask to hold the regions to be removed\n",
        "    mask_to_remove = np.zeros_like(binary_image, dtype=bool)\n",
        "\n",
        "    # Iterate over the regions\n",
        "    for region in regions:\n",
        "        # If the region area is below the threshold, add it to the mask\n",
        "        if region.area < area_threshold:\n",
        "            mask_to_remove[labeled_image == region.label] = True\n",
        "\n",
        "    # Set the regions in the mask to 0 in the original image\n",
        "    binary_image[mask_to_remove] = 0\n",
        "\n",
        "    return binary_image\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def adaptive_gamma_lightening(img, block_size, gamma_min, gamma_max):\n",
        "    \"\"\"\n",
        "    Funzione per il calcolo adattivo localizzato della funzione gamma\n",
        "    Parametri:\n",
        "    - img: immagine su cui lavorare\n",
        "    - block_size: dimensione dei blocchi in cui viene divisa l'immagine per il calcolo locale della funzione di gamma\n",
        "    - gamma_min: valore minimo che può assumere la gamma calcolata\n",
        "    - gamma_max: valore massimo che può assumere la gamma calcolata\n",
        "\n",
        "    Restituisce:\n",
        "    - corrected_img: immagine con gamma modificata e valori compresi tra 0 e 1\n",
        "    \"\"\"\n",
        "\n",
        "    h, w = img.shape[:2]\n",
        "    corrected_img = np.zeros_like(img, dtype=np.float32)\n",
        "\n",
        "    for y in range(0, h, block_size):\n",
        "        for x in range(0, w, block_size):\n",
        "            block = img[y:y+block_size, x:x+block_size]\n",
        "            avg_brightness = np.mean(block)\n",
        "\n",
        "            # Mappare avg_brightness a un intervallo adatto per la sigmoide\n",
        "            mapped_brightness = (avg_brightness - 0.5) * 12\n",
        "\n",
        "            # Applicare la sigmoide\n",
        "            sigmoid_value = sigmoid(mapped_brightness)\n",
        "\n",
        "            # Scala e trasforma l'output della sigmoide per rientrare nel range [gamma_min, gamma_max]\n",
        "            gamma = gamma_min + (gamma_max - gamma_min) * sigmoid_value\n",
        "\n",
        "            corrected_block = np.power(block, gamma)\n",
        "            corrected_img[y:y+block_size, x:x+block_size] = corrected_block\n",
        "\n",
        "    return np.clip(corrected_img, 0, 1)\n",
        "\n",
        "def divide_into_blocks(img, block_size):\n",
        "    \"\"\"\n",
        "    Funzione per dividere in sottoimmagine l'immagine\n",
        "\n",
        "    Parametri:\n",
        "    - img: immagine su cui lavorare\n",
        "    - block_size: dimensione dei blocchi in cui viene divisa l'immagine per il calcolo locale della funzione di gamma\n",
        "\n",
        "    Restituisce:\n",
        "    - blocks: lista contenente le sottoimmagini in cui si è divisa l'immagine originale\n",
        "    \"\"\"\n",
        "    blocks = []\n",
        "    for i in range(0, img.shape[0], block_size[0]):\n",
        "        for j in range(0, img.shape[1], block_size[1]):\n",
        "            block = img[i:i + block_size[0], j:j + block_size[1]]\n",
        "            if block.shape[0] != block_size[0] or block.shape[1] != block_size[1]:\n",
        "                block = np.pad(block, ((0, block_size[0] - block.shape[0]), (0, block_size[1] - block.shape[1])), 'constant')\n",
        "            blocks.append(block)\n",
        "    return blocks\n",
        "\n",
        "def reassemble_blocks(blocks, original_shape, block_size):\n",
        "    \"\"\"\n",
        "    Funzione per riassemblare l'immagine originale partendo dalle singole sottoimmagini\n",
        "\n",
        "    Parametri:\n",
        "    - blocks: lista contenente tutte le sottoimmagini da riassemblare\n",
        "    - original_shape: dimensione dell'immaigne originale\n",
        "    - block_size: dimensione dei blocchi in cui viene divisa l'immagine per il calcolo locale della funzione di gamma\n",
        "\n",
        "    Restituisce:\n",
        "    - final_image_cropped: immagine originale, ricomposta dalle singole sottoimmagini\n",
        "    \"\"\"\n",
        "    # Calcola il numero di blocchi per riga e per colonna\n",
        "    rows = original_shape[0] // block_size[0]\n",
        "    cols = original_shape[1] // block_size[1]\n",
        "\n",
        "    # Se l'immagine originale non è un multiplo della dimensione del blocco, aggiungi un'altra riga/colonna\n",
        "    if original_shape[0] % block_size[0] != 0:\n",
        "        rows += 1\n",
        "    if original_shape[1] % block_size[1] != 0:\n",
        "        cols += 1\n",
        "\n",
        "    # Crea un'immagine vuota per l'immagine finale riassemblata\n",
        "    final_image = np.zeros((rows * block_size[0], cols * block_size[1]), dtype=np.float32)\n",
        "\n",
        "    # Inserisci ogni blocco nell'immagine finale\n",
        "    for idx, block in enumerate(blocks):\n",
        "        row = (idx // cols) * block_size[0]\n",
        "        col = (idx % cols) * block_size[1]\n",
        "        final_image[row:row + block_size[0], col:col + block_size[1]] = block\n",
        "\n",
        "    # Ritaglia l'immagine finale per farla corrispondere alle dimensioni originali\n",
        "    final_image_cropped = final_image[:original_shape[0], :original_shape[1]]\n",
        "    return final_image_cropped\n",
        "\n",
        "\n",
        "def prepare_block(block):\n",
        "    '''\n",
        "    Funzione che permette di trasformare in tensore l'immagine ricevuta\n",
        "\n",
        "    Parametri:\n",
        "    - block: blocco contenente sottoimmagine da trasformare in tensore per passarla alla rete\n",
        "\n",
        "    Restituisce:\n",
        "    - block: tensore dell'immagine con aggiunta la dimensione del batch (1)\n",
        "    '''\n",
        "    transformation = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    block = transformation(block)\n",
        "    return block.unsqueeze(0)      # Aggiunge dimensione del batch al tensore, altrimenti contenente solo [canali,altezza,larghezza]\n",
        "\n",
        "def infer(model, block, device):\n",
        "    '''\n",
        "    Funzione per eseguire l'inferenza del blocco\n",
        "\n",
        "    Parametri:\n",
        "    - model: modello della rete da usare per fare inference\n",
        "    - block: blocco sul quale eseguire inferenza\n",
        "    - device: dispositivo da usare per fare l'inferenza\n",
        "\n",
        "    Restitusice:\n",
        "    - mask: matrice in cui i\n",
        "    '''\n",
        "    block = block.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(block)\n",
        "        mask = output.sigmoid().squeeze()\n",
        "    return mask\n",
        "\n",
        "def preprocess(image_path):\n",
        "\n",
        "    image = io.imread(image_path)\n",
        "\n",
        "    # Eye masks\n",
        "    dim=image.shape\n",
        "    gray_image = color.rgb2gray(image)\n",
        "    gray_image = img_as_float(gray_image)\n",
        "    gray_image=gaussian_filter(gray_image,sigma=5,mode='constant', cval=0.0,truncate=2.0)\n",
        "    gray_image = exposure.equalize_adapthist(gray_image,clip_limit=0.019)\n",
        "    threshold = filters.threshold_minimum(gray_image)\n",
        "    bin_img = gray_image>threshold\n",
        "    closed_image = morphology.remove_small_holes(bin_img,area_threshold=(dim[0]/8)**2*3)\n",
        "    label_image = measure.label(closed_image)\n",
        "    regions = measure.regionprops(label_image)\n",
        "\n",
        "    if regions:\n",
        "        largest_region = max(regions, key=lambda r: r.area)\n",
        "        eye_mask = label_image == largest_region.label\n",
        "    else:\n",
        "        eye_mask = closed_image\n",
        "\n",
        "    image_green = image[:, :, 1]*eye_mask  # Estrai solo il canale verde\n",
        "\n",
        "    image_green = img_as_float(image_green)\n",
        "\n",
        "    image_green = min_max_normalization(image_green)\n",
        "\n",
        "    # Apply gaussian filter\n",
        "    ris_min = min(image_green.shape)\n",
        "    # Calculate the result of ris_min / 100\n",
        "    value = ris_min / 100\n",
        "\n",
        "    # Convert result to the nearest integer\n",
        "    nearest_int = int(value)\n",
        "\n",
        "    # If nearest_int is odd and not greater than result, return it\n",
        "    if nearest_int % 2 != 0 and nearest_int <= value:\n",
        "        dimension = nearest_int\n",
        "    else:\n",
        "        # If nearest_int is even or greater than result, return the previous odd number\n",
        "        dimension = (nearest_int - 1 if nearest_int % 2 == 0 else nearest_int-2)\n",
        "\n",
        "    #sigma = 0.15*dimension\n",
        "    sigma=2.5\n",
        "    truncate = ((dimension-1)/2-0.5)/sigma\n",
        "\n",
        "    image_green_gaussian = filters.gaussian(image_green, sigma=sigma, truncate=truncate)\n",
        "\n",
        "    # Apply CLAHE equalisation\n",
        "    image_green_clahe = exposure.equalize_adapthist(image_green_gaussian, clip_limit=0.01)\n",
        "\n",
        "    # Apply gamma correction\n",
        "    image_gamma = (adaptive_gamma_lightening(image_green_clahe, block_size=5, gamma_min=0.7, gamma_max=1))*eye_mask\n",
        "\n",
        "    # Apply Black Top-Hat Transform\n",
        "    radius=int(max(image_gamma.shape)*0.0045)\n",
        "    radius=np.clip(radius,8,15)\n",
        "    transformed_img = exposure.rescale_intensity(morphology.black_tophat(image_gamma, footprint=morphology.disk(radius)))\n",
        "\n",
        "    image_pre = (image_gamma-transformed_img)\n",
        "    image_end = np.clip(image_pre,0,1)\n",
        "\n",
        "    desired_height = round(image_end.shape[0] / 256) * 256\n",
        "    desired_width = round(image_end.shape[1] / 256) * 256\n",
        "\n",
        "    original_height = image_end.shape[0]\n",
        "    original_width = image_end.shape[1]\n",
        "\n",
        "    # Verifica se l'altezza e la larghezza sono entrambe multipli di 256\n",
        "    height_is_multiple = original_height % 256 == 0\n",
        "    width_is_multiple = original_width % 256 == 0\n",
        "\n",
        "    flag = 0\n",
        "\n",
        "    if height_is_multiple and width_is_multiple:\n",
        "        # Se entrambe le dimensioni sono già multipli di 256, non fare nulla\n",
        "        image_resized = image_end\n",
        "    elif height_is_multiple:\n",
        "        # Se solo l'altezza non è un multiplo di 256, aggiusta solo l'altezza\n",
        "        image_resized = resize(image_end, (desired_height, image_end.shape[1]), anti_aliasing=True)\n",
        "        flag = 1\n",
        "    elif width_is_multiple:\n",
        "        # Se solo la larghezza non è un multiplo di 256, aggiusta solo la larghezza\n",
        "        image_resized = resize(image_end, (image_end.shape[0], desired_width), anti_aliasing=True)\n",
        "        flag = 1\n",
        "    else:\n",
        "        # Se entrambe le dimensioni non sono multipli di 256, aggiusta entrambe\n",
        "        image_resized = resize(image_end, (desired_height, desired_width), anti_aliasing=True)\n",
        "        flag = 1\n",
        "\n",
        "    preprocessedImage = image_resized\n",
        "\n",
        "    return preprocessedImage, original_height, original_width, flag\n",
        "\n",
        "def postprocess(image, v_bin, distance_threshold, thickness):\n",
        "\n",
        "    final_mask_clipped = np.clip(image, 0, 1)\n",
        "    final_mask_binary = (final_mask_clipped>v_bin)\n",
        "\n",
        "    # Inizio post-process\n",
        "    height, width = final_mask_binary.shape\n",
        "    skeleton_image = morphology.skeletonize(final_mask_binary)\n",
        "    labeled_skeleton = measure.label(skeleton_image)\n",
        "    regions = measure.regionprops(labeled_skeleton)\n",
        "    bounding_boxes = [region.bbox for region in regions]\n",
        "\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        segment_kdtrees = list(executor.map(KDTree, [region.coords for region in regions]))\n",
        "\n",
        "    # Trova i punti più vicini in parallelo\n",
        "    close_points = []\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        future_to_segment = {(executor.submit(check_and_search, regions[i], regions[j], segment_kdtrees[i], segment_kdtrees[j], bounding_boxes[i], bounding_boxes[j], distance_threshold)): (i, j) for i in range(len(regions)) for j in range(i+1, len(regions))}\n",
        "        for future in as_completed(future_to_segment):\n",
        "            result = future.result()\n",
        "            if result:\n",
        "                close_points.append(result)\n",
        "\n",
        "     # Aggiornamento e salvataggio dell'immagine\n",
        "    updated_mask_points = np.copy(final_mask_binary)\n",
        "    for pt1, pt2 in close_points:\n",
        "        rr, cc = draw_thick_line(pt1, pt2, thickness)\n",
        "\n",
        "        # Accoppiare le coordinate rr e cc prima di filtrarle\n",
        "        coords = np.column_stack((rr, cc))\n",
        "\n",
        "        # Filtrare le coordinate che sono all'interno dei limiti dell'immagine\n",
        "        valid_coords = coords[(coords[:, 0] >= 0) & (coords[:, 0] < height) & (coords[:, 1] >= 0) & (coords[:, 1] < width)]\n",
        "\n",
        "        # Separare le coordinate filtrate rr e cc\n",
        "        rr_valid, cc_valid = valid_coords[:, 0], valid_coords[:, 1]\n",
        "        updated_mask_points[rr_valid, cc_valid] = 1\n",
        "\n",
        "    height, width = updated_mask_points.shape\n",
        "    soglia=np.ceil((height*width)*0.000025)\n",
        "    cleaned=remove_small_regions(updated_mask_points, soglia)\n",
        "    final_mask_uint8 = img_as_ubyte(cleaned)\n",
        "\n",
        "    return final_mask_uint8\n",
        "\n",
        "# Definizione architettura rete neurale da usare per l'inference\n",
        "class UNet1(nn.Module):\n",
        "    \"\"\"\n",
        "    Vista l'assenza di modifiche rispetto alla rete originalmente proposta, si mantiene lo stesso commento\n",
        "\n",
        "    U-Net architecture for semantic segmentation.\n",
        "    This model consists of an encoder (contracting path), a bottleneck, and a decoder (expansive path).\n",
        "    Each step in the encoder consists of two 3x3 convolutions followed by a ReLU and a 2x2 max pooling.\n",
        "    The decoder upsamples the features and concatenates them with the corresponding encoder features,\n",
        "    followed by two 3x3 convolutions and a ReLU.\n",
        "    It is based on the U-Net paper: https://arxiv.org/abs/1505.04597\n",
        "\n",
        "    Args:\n",
        "        input_channels (int): Number of input channels. Default is 3 for RGB images.\n",
        "        out_classes (int): Number of output classes. Default is 1 for binary segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_channels=1, out_classes=1):\n",
        "        super(UNet1, self).__init__()\n",
        "\n",
        "        # Contracting path\n",
        "        self.enc1 = self.conv_block(input_channels, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Lowest resolution\n",
        "        self.bottleneck = self.conv_block(512, 1024)\n",
        "\n",
        "        # Expansive path\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec4 = self.conv_block(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = self.conv_block(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = self.conv_block(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = self.conv_block(128, 64)\n",
        "        self.out = nn.Conv2d(64, out_classes, kernel_size=1)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        \"\"\"\n",
        "        Returns a block that performs two 3x3 convolutions followed by a ReLU. With respect to the original paper, we add batch normalization. It's a method\n",
        "        that allow us to train faster and higher accuracy networks.\n",
        "\n",
        "        Args:\n",
        "            in_channels (int): Number of input channels.\n",
        "            out_channels (int): Number of output channels.\n",
        "\n",
        "        Returns:\n",
        "            torch.nn.Sequential: A sequential container of two 3x3 convolutions followed by ReLUs.\n",
        "        \"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),   # Modificato\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the U-Net model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size, input_channels, height, width).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (batch_size, out_classes, height, width).\n",
        "        \"\"\"\n",
        "        # Contracting path\n",
        "        x1 = self.enc1(x) # first double convolution\n",
        "        x2 = self.enc2(self.pool(x1)) # apply pooling and second double convolution\n",
        "        x3 = self.enc3(self.pool(x2))\n",
        "        x4 = self.enc4(self.pool(x3))\n",
        "\n",
        "        # Lowest resolution\n",
        "        x5 = self.bottleneck(self.pool(x4))\n",
        "\n",
        "        # Expansive path, repeat upconv and concatenation as needed\n",
        "        x = self.upconv4(x5)\n",
        "        x = self.dec4(torch.cat([x, x4], dim=1))  # Concatenating with conv4\n",
        "        x = self.upconv3(x)\n",
        "        x = self.dec3(torch.cat([x, x3], dim=1))  # Concatenating with conv3\n",
        "        x = self.upconv2(x)\n",
        "        x = self.dec2(torch.cat([x, x2], dim=1))  # Concatenating with conv2\n",
        "        x = self.upconv1(x)\n",
        "        x = self.dec1(torch.cat([x, x1], dim=1))  # Concatenating with conv1\n",
        "\n",
        "\n",
        "        x = self.out(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "OiczEY31-guR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nella sezione seguente è presente il codice per la segmentazione delle immagini. Al fine di rendere la sua esecuzione ciclica robusta contro possibili errori presenti in una singola immagine, si sono utilizza dei costrutti try-except che evidenziano sul terminale eventuali errori sorti."
      ],
      "metadata": {
        "id": "m7D1C8lb5VH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREAZIONE E CARICAMENTO RETE\n",
        "try:\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = UNet1()\n",
        "    model.load_state_dict(torch.load(model_path+'/'+nome_trial+'.pth'))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "except Exception as e:\n",
        "    print(f\"Errore durante l'inizializzazione della rete!: {e}\")\n",
        "\n",
        "# Avvio del ciclo che segmenta tutte le immagini presenti nella cartella indicata\n",
        "for idx in tqdm(range(0,len(image_paths))):\n",
        "\n",
        "    image_path=image_paths[idx]\n",
        "\n",
        "    # PREPROCESS\n",
        "    try:\n",
        "        image_uint, original_height, original_width, flag = preprocess(image_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante il preprocess dell'immagine {image_path}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    # DIVISIONE IN BLOCCHI E INFERENCE\n",
        "    try:\n",
        "        blocks = divide_into_blocks(image_uint, block_size)\n",
        "        processed_blocks = []\n",
        "        for block in blocks:\n",
        "            prepared_block = prepare_block(block).to(device)            # Sposta il blocco preparato sul dispositivo per la segmentazione\n",
        "            mask = infer(model, prepared_block, device)\n",
        "            mask_n = mask.cpu().numpy()                                 # Riporta su CPU la maschera segmentata per proseguire l'elaborazione, trasformandola in numpy array\n",
        "            processed_blocks.append(mask_n)\n",
        "\n",
        "        final_mask = reassemble_blocks(processed_blocks, image_uint.shape, block_size)\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante la divisione o inference dell'immagine!: {e}\")\n",
        "\n",
        "    # POSTPROCESS\n",
        "    try:\n",
        "        if flag:\n",
        "            final_mask = resize(final_mask, (original_height, original_width), anti_aliasing=True)\n",
        "        final_mask_uint8 = postprocess(final_mask, v_bin, distance_threshold, thickness)\n",
        "\n",
        "        #==================================================================================================== DEFINIZIONE CARTELLA DI OUTPUT =======================================================\n",
        "        # Definzione cartella di output\n",
        "        results_folder = working_folder+'/Output_masks/'\n",
        "        #==================================================================================================== /DEFINIZIONE CARTELLA DI OUTPUT ======================================================\n",
        "\n",
        "        if not os.path.exists(results_folder):\n",
        "                os.makedirs(results_folder)\n",
        "                print('\\n Creata la cartella di Output: '+results_folder)\n",
        "        filename_image = os.path.basename(image_path)\n",
        "        complete_filename_image = results_folder+'/'+filename_image\n",
        "        io.imsave(complete_filename_image, final_mask_uint8)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Errore durante il salvataggio dell'immagine!: {e}\")"
      ],
      "metadata": {
        "id": "MUVTC-ZM-hXD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}